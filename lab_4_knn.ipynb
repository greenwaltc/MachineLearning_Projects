{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DVL7_bgmIAPR"
   },
   "source": [
    "# K-Nearest Neighbor Lab\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "6ZbYjZZZ_yLV"
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.io import arff\n",
    "from IPython.core.display import display\n",
    "\n",
    "import math\n",
    "import copy\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pdb\n",
    "\n",
    "import warnings; warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sCcEPx5VIORj"
   },
   "source": [
    "## 1. (40%) Correctly implement the k-nearest neighbor (KNN) algorithm and the KNN regression algorithm\n",
    "\n",
    "### Code requirements\n",
    "- Use Euclidean distance to decide closest neighbors. \n",
    "- Include optional distance weighting for both algorithms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "id": "_a2KSZ_7AN0G"
   },
   "outputs": [],
   "source": [
    "class KNNClassifier(BaseEstimator,ClassifierMixin):\n",
    "    def __init__(self, columntype=[], weight_type='inverse_distance', knn=3): ## add parameters here\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            columntype for each column tells you if continues[real] or if nominal[categoritcal].\n",
    "            weight_type: inverse_distance voting or if non distance weighting. Options = [\"no_weight\",\"inverse_distance\"]\n",
    "        \"\"\"\n",
    "        self.columntype = columntype #Note This won't be needed until part 5\n",
    "        self.weight_type = weight_type\n",
    "        self.knn = knn\n",
    "\n",
    "    def fit(self, X, y, labels=None):\n",
    "        \"\"\" Fit the data; run the algorithm (for this lab really just saves the data :D)\n",
    "        Args:\n",
    "            X (array-like): A 2D numpy array with the training data, excluding targets\n",
    "            y (array-like): A 2D numpy array with the training targets\n",
    "        Returns:\n",
    "            self: this allows this to be chained, e.g. model.fit(X,y).predict(X_test)\n",
    "        \"\"\"\n",
    "        self.X, self.y = X, y\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\" Predict all classes for a dataset X\n",
    "        Args:\n",
    "            X (array-like): A 2D numpy array with the training data, excluding targets\n",
    "        Returns:\n",
    "            array, shape (n_samples,)\n",
    "                Predicted target values per element in X.\n",
    "        \"\"\"\n",
    "\n",
    "        predictions = np.zeros(X.shape[0])\n",
    "\n",
    "        for i in range(X.shape[0]):\n",
    "            instance = X[i, :]\n",
    "            distances = (self.X - instance)**2\n",
    "\n",
    "            if np.any(self.columntype):\n",
    "                mask = (self.X == instance)\n",
    "                nominal_columns = np.where(self.columntype == 1)\n",
    "                distances[nominal_columns] = mask[nominal_columns]\n",
    "\n",
    "            distances = distances.sum(axis=1)\n",
    "            distances = np.sqrt(distances)\n",
    "            predicted_class = self._predicted_class(self.y, distances)\n",
    "            predictions[i] = predicted_class\n",
    "\n",
    "        return predictions\n",
    "\n",
    "    def _predicted_class(self, classes, distances):\n",
    "\n",
    "        data = np.append(classes.reshape(-1, 1), distances.reshape(-1, 1), axis=1)\n",
    "        data = data[data[:, 1].argsort()]\n",
    "        data = data[:self.knn, :]\n",
    "\n",
    "        if self.weight_type == 'inverse_distance':\n",
    "            data[:, 1] = np.where(data[:, 1] != 0, 1/(data[:, 1]**2), np.inf)\n",
    "        else:\n",
    "            data[:, 1] = 1\n",
    "\n",
    "        result = np.bincount(data[:, 0].reshape(-1).astype(int), weights=data[:, 1].reshape(-1))\n",
    "        return np.argmax(result)\n",
    "\n",
    "    #Returns the Mean score given input data and labels\n",
    "    def score(self, X, y):\n",
    "        \"\"\" Return accuracy of model on a given dataset. Must implement own score function.\n",
    "        Args:\n",
    "            X (array-like): A 2D numpy array with data, excluding targets\n",
    "            y (array-like): A 2D numpy array with targets\n",
    "        Returns:\n",
    "            score : float\n",
    "                Mean accuracy of self.predict(X) wrt. y.\n",
    "        \"\"\"\n",
    "        predictions = self.predict(X)\n",
    "        return (predictions == y.reshape(-1)).mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KNNRegressor(BaseEstimator,ClassifierMixin):\n",
    "    def __init__(self, columntype=[], weight_type='inverse_distance', knn=3): ## add parameters here\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            columntype for each column tells you if continues[real] or if nominal[categoritcal].\n",
    "            weight_type: inverse_distance voting or if non distance weighting. Options = [\"no_weight\",\"inverse_distance\"]\n",
    "        \"\"\"\n",
    "        self.columntype = columntype #Note This won't be needed until part 5\n",
    "        self.weight_type = weight_type\n",
    "        self.knn = knn\n",
    "\n",
    "    def fit(self, X, y, labels=None):\n",
    "        \"\"\" Fit the data; run the algorithm (for this lab really just saves the data :D)\n",
    "        Args:\n",
    "            X (array-like): A 2D numpy array with the training data, excluding targets\n",
    "            y (array-like): A 2D numpy array with the training targets\n",
    "        Returns:\n",
    "            self: this allows this to be chained, e.g. model.fit(X,y).predict(X_test)\n",
    "        \"\"\"\n",
    "        self.X, self.y = X, y\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\" Predict all classes for a dataset X\n",
    "        Args:\n",
    "            X (array-like): A 2D numpy array with the training data, excluding targets\n",
    "        Returns:\n",
    "            array, shape (n_samples,)\n",
    "                Predicted target values per element in X.\n",
    "        \"\"\"\n",
    "\n",
    "        predictions = np.zeros(X.shape[0])\n",
    "\n",
    "        for i in range(X.shape[0]):\n",
    "            instance = X[i, :]\n",
    "            distances = (self.X - instance)**2\n",
    "\n",
    "            if np.any(self.columntype):\n",
    "                mask = (self.X == instance)\n",
    "                nominal_columns = np.where(self.columntype == 1)\n",
    "                distances[nominal_columns] = mask[nominal_columns]\n",
    "\n",
    "            distances = distances.sum(axis=1)\n",
    "            distances = np.sqrt(distances)\n",
    "            predicted_class = self._predicted_class(self.y, distances)\n",
    "            predictions[i] = predicted_class\n",
    "\n",
    "        return predictions\n",
    "\n",
    "    def _predicted_class(self, classes, distances):\n",
    "\n",
    "        data = np.append(classes.reshape(-1, 1), distances.reshape(-1, 1), axis=1)\n",
    "        data = data[data[:, 1].argsort()]\n",
    "        data = data[:self.knn, :]\n",
    "\n",
    "        if self.weight_type == 'inverse_distance':\n",
    "            data[:, 1] = np.where(data[:, 1] != 0, 1/(data[:, 1]**2), np.inf)\n",
    "        else:\n",
    "            data[:, 1] = 1\n",
    "\n",
    "        result = np.bincount(data[:, 0].reshape(-1).astype(int), weights=data[:, 1].reshape(-1))\n",
    "        return np.argmax(result)\n",
    "\n",
    "    #Returns the Mean score given input data and labels\n",
    "    def score(self, X, y):\n",
    "        \"\"\" Return accuracy of model on a given dataset. Must implement own score function.\n",
    "        Args:\n",
    "            X (array-like): A 2D numpy array with data, excluding targets\n",
    "            y (array-like): A 2D numpy array with targets\n",
    "        Returns:\n",
    "            score : float\n",
    "                Mean accuracy of self.predict(X) wrt. y.\n",
    "        \"\"\"\n",
    "        predictions = self.predict(X)\n",
    "        return (predictions == y.reshape(-1)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(filename):\n",
    "    data = arff.loadarff(filename)\n",
    "    df = pd.DataFrame(data[0])\n",
    "\n",
    "    for i in range(len(df.dtypes)):\n",
    "        if df.dtypes.astype(str).iloc[i] == 'object':\n",
    "            column = df.columns[i]\n",
    "            df[column] = df[column] \\\n",
    "                            .astype(str).str \\\n",
    "                            .split(\"\\'\", expand=True) \\\n",
    "                            .iloc[:,1]\n",
    "    return df\n",
    "\n",
    "def encode_X(X1, X2):\n",
    "    columns = X1.columns\n",
    "\n",
    "    for column in columns:\n",
    "        if X1[column].dtype == 'object':\n",
    "            le = LabelEncoder()\n",
    "            le.fit(X1[column])\n",
    "            X1[column] = le.transform(X1[column])\n",
    "            X2[column] = le.transform(X2[column])\n",
    "   \n",
    "    return X1, X2\n",
    "\n",
    "def encode_y(y1, y2):\n",
    "    name = y1.name\n",
    "    le = LabelEncoder()\n",
    "    le.fit(y1)\n",
    "    y1 = le.transform(y1)\n",
    "    y2 = le.transform(y2)\n",
    "    return pd.DataFrame(y1, columns=[name]), pd.DataFrame(y2, columns=[name])\n",
    "\n",
    "def get_column_types(df):\n",
    "    c_types = df.dtypes.astype(str)\n",
    "    c_types = c_types.map({'float64': 0, 'object': 1})\n",
    "    return c_types.to_numpy().reshape(-1)[:-1]\n",
    "\n",
    "def normalize(X1, X2):\n",
    "    len_X1 = X1.shape[0]\n",
    "    X = np.append(X1, X2, axis=0)\n",
    "    feature_mins = X.min(axis=0)\n",
    "    feature_maxs = X.max(axis=0)\n",
    "\n",
    "    X = (X-feature_mins) / (feature_maxs - feature_mins)\n",
    "    \n",
    "    return X[:len_X1, :], X[len_X1:, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Debug and Evaluation\n",
    "\n",
    "Debug and Evaluate your model using the parameters below:\n",
    "\n",
    "- Use distance weighting\n",
    "- KNN = 3 (three nearest neighbors)\n",
    "- Don’t normalize the data\n",
    "- Use Euclidean Distance\n",
    "\n",
    "---\n",
    "\n",
    "### 1.1.1 Debug\n",
    "\n",
    "- Use this [training set](https://raw.githubusercontent.com/cs472ta/CS472/master/datasets/glass_train.arff) and this [test set](https://raw.githubusercontent.com/cs472ta/CS472/master/datasets/glass_test.arff)\n",
    "- Use distance weighting\n",
    "- KNN = 3 (three nearest neighbors)\n",
    "- Don’t normalize the data\n",
    "- Use Euclidean Distance\n",
    "\n",
    "Expected Results:\n",
    "- Not using inverse weighted distancing = roughly [68.29%]\n",
    "- Link to [debug solution](https://github.com/cs472ta/CS472/blob/master/debug_solutions/glass_no_inv_prediction.csv)\n",
    "\n",
    "- Using inverse weighted distancing = roughly [74.39%]\n",
    "- Link to [debug solution](https://github.com/cs472ta/CS472/blob/master/debug_solutions/glass_inv_prediction.csv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score with inverted distance weighting: 0.7439\n",
      "Score with no inverted distance weighting: 0.6829\n"
     ]
    }
   ],
   "source": [
    "# Load glass data\n",
    "glass_trainDF = load_data('datasets/glass_train.arff')\n",
    "glass_testDF = load_data('datasets/glass_test.arff')\n",
    "\n",
    "# Get column types\n",
    "column_types = get_column_types(glass_trainDF)\n",
    "\n",
    "glass_X_trainDF, glass_y_trainDF = glass_trainDF.iloc[:, :-1], glass_trainDF.iloc[:, -1]\n",
    "glass_X_testDF, glass_y_testDF = glass_testDF.iloc[:, :-1], glass_testDF.iloc[:, -1]\n",
    "\n",
    "glass_X_train, glass_X_test = encode_X(glass_X_trainDF, glass_X_testDF)\n",
    "glass_y_train, glass_y_test = encode_y(glass_y_trainDF, glass_y_testDF)\n",
    "\n",
    "X_train = glass_X_train.to_numpy()\n",
    "X_test = glass_X_test.to_numpy()\n",
    "y_train = glass_y_train.to_numpy()\n",
    "y_test = glass_y_test.to_numpy()\n",
    "\n",
    "# Train on training set\n",
    "glass_knn_d_weighting = KNNClassifier(columntype=column_types)\n",
    "glass_knn_nd_weighting = KNNClassifier(columntype=column_types, weight_type=None)\n",
    "glass_knn_d_weighting.fit(X_train, y_train)\n",
    "glass_knn_nd_weighting.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test set\n",
    "glass_score_d_weighting = glass_knn_d_weighting.score(X_test, y_test)\n",
    "glass_score_nd_weighting = glass_knn_nd_weighting.score(X_test, y_test)\n",
    "print(\"Score with inverted distance weighting: %.4f\" % glass_score_d_weighting)\n",
    "print(\"Score with no inverted distance weighting: %.4f\" % glass_score_nd_weighting)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.2 Evaluate\n",
    "\n",
    "We will evaluate your model based on its performance on the [diabetes](https://archive.ics.uci.edu/ml/datasets/Diabetes) problem.\n",
    "- Use this [training set](https://raw.githubusercontent.com/cs472ta/CS472/master/datasets/diabetes_train.arff) and this [test set](https://raw.githubusercontent.com/cs472ta/CS472/master/datasets/diabetes_test.arff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation dataset KNN accuracy: 0.891\n"
     ]
    }
   ],
   "source": [
    "# Load diabetes data\n",
    "diabetes_trainDF = load_data('datasets/diabetes_train.arff')\n",
    "diabetes_testDF = load_data('datasets/diabetes_test.arff')\n",
    "\n",
    "# Get column types\n",
    "column_types = get_column_types(diabetes_trainDF)[:-1]\n",
    "\n",
    "diabetes_X_trainDF, diabetes_y_trainDF = diabetes_trainDF.iloc[:, :-1], diabetes_trainDF.iloc[:, -1]\n",
    "diabetes_X_testDF, diabetes_y_testDF = diabetes_testDF.iloc[:, :-1], diabetes_testDF.iloc[:, -1]\n",
    "\n",
    "diabetes_X_train, diabetes_X_test = encode_X(diabetes_X_trainDF, diabetes_X_testDF)\n",
    "diabetes_y_train, diabetes_y_test = encode_y(diabetes_y_trainDF, diabetes_y_testDF)\n",
    "\n",
    "# Train on training set\n",
    "X_train = diabetes_X_train.to_numpy()\n",
    "X_test = diabetes_X_test.to_numpy()\n",
    "y_train = diabetes_y_train.to_numpy()\n",
    "y_test = diabetes_y_test.to_numpy()\n",
    "\n",
    "diabetes_knn = KNNClassifier(columntype=column_types)\n",
    "diabetes_knn.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test set\n",
    "score = diabetes_knn.score(X_test, y_test)\n",
    "print(\"Evaluation dataset KNN accuracy: %.3f\" % score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9vWiTdlbR2Xh"
   },
   "source": [
    "## 2. (10%) Use the k-nearest neighbor algorithm (without distance weighting) for the [magic telescope](http://archive.ics.uci.edu/ml/datasets/MAGIC+Gamma+Telescope) problem\n",
    "\n",
    "- Use this [training set](https://raw.githubusercontent.com/cs472ta/CS472/master/datasets/magic_telescope_train.arff) and this [test set](https://raw.githubusercontent.com/cs472ta/CS472/master/datasets/magic_telescope_test.arff) \n",
    "\n",
    "### 2.1\n",
    "- Try it with k=3 and without normalization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fLength</th>\n",
       "      <th>fWidth</th>\n",
       "      <th>fSize</th>\n",
       "      <th>fConc</th>\n",
       "      <th>fConc1</th>\n",
       "      <th>fAsym</th>\n",
       "      <th>fM3Long</th>\n",
       "      <th>fM3Trans</th>\n",
       "      <th>fAlpha</th>\n",
       "      <th>fDist</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22.7815</td>\n",
       "      <td>14.9526</td>\n",
       "      <td>2.4362</td>\n",
       "      <td>0.4982</td>\n",
       "      <td>0.2509</td>\n",
       "      <td>-14.2836</td>\n",
       "      <td>-9.3635</td>\n",
       "      <td>13.0939</td>\n",
       "      <td>3.0779</td>\n",
       "      <td>141.562</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>40.6756</td>\n",
       "      <td>15.5940</td>\n",
       "      <td>2.7447</td>\n",
       "      <td>0.2772</td>\n",
       "      <td>0.1449</td>\n",
       "      <td>19.6226</td>\n",
       "      <td>9.0297</td>\n",
       "      <td>7.4157</td>\n",
       "      <td>15.4260</td>\n",
       "      <td>193.234</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fLength   fWidth   fSize   fConc  fConc1    fAsym  fM3Long  fM3Trans  \\\n",
       "0  22.7815  14.9526  2.4362  0.4982  0.2509 -14.2836  -9.3635   13.0939   \n",
       "1  40.6756  15.5940  2.7447  0.2772  0.1449  19.6226   9.0297    7.4157   \n",
       "\n",
       "    fAlpha    fDist class  \n",
       "0   3.0779  141.562     g  \n",
       "1  15.4260  193.234     g  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12354, 11)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fLength</th>\n",
       "      <th>fWidth</th>\n",
       "      <th>fSize</th>\n",
       "      <th>fConc</th>\n",
       "      <th>fConc1</th>\n",
       "      <th>fAsym</th>\n",
       "      <th>fM3Long</th>\n",
       "      <th>fM3Trans</th>\n",
       "      <th>fAlpha</th>\n",
       "      <th>fDist</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30.5540</td>\n",
       "      <td>21.1807</td>\n",
       "      <td>2.7509</td>\n",
       "      <td>0.2715</td>\n",
       "      <td>0.1500</td>\n",
       "      <td>2.1798</td>\n",
       "      <td>-20.8938</td>\n",
       "      <td>-15.2262</td>\n",
       "      <td>2.2982</td>\n",
       "      <td>197.390</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>59.2444</td>\n",
       "      <td>10.4634</td>\n",
       "      <td>2.8051</td>\n",
       "      <td>0.4019</td>\n",
       "      <td>0.1971</td>\n",
       "      <td>49.4360</td>\n",
       "      <td>25.1317</td>\n",
       "      <td>7.0386</td>\n",
       "      <td>71.0828</td>\n",
       "      <td>48.129</td>\n",
       "      <td>h</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fLength   fWidth   fSize   fConc  fConc1    fAsym  fM3Long  fM3Trans  \\\n",
       "0  30.5540  21.1807  2.7509  0.2715  0.1500   2.1798 -20.8938  -15.2262   \n",
       "1  59.2444  10.4634  2.8051  0.4019  0.1971  49.4360  25.1317    7.0386   \n",
       "\n",
       "    fAlpha    fDist class  \n",
       "0   2.2982  197.390     g  \n",
       "1  71.0828   48.129     h  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6666, 11)\n"
     ]
    }
   ],
   "source": [
    "# Load diabetes data\n",
    "magic_telescope_trainDF = load_data('datasets/magic_telescope_train.arff')\n",
    "magic_telescope_testDF = load_data('datasets/magic_telescope_test.arff')\n",
    "\n",
    "display(magic_telescope_trainDF.head(2))\n",
    "print(magic_telescope_trainDF.shape)\n",
    "display(magic_telescope_testDF.head(2))\n",
    "print(magic_telescope_testDF.shape)\n",
    "\n",
    "# Get column types\n",
    "magic_telescope_column_types = get_column_types(magic_telescope_trainDF)[:-1]\n",
    "\n",
    "# X and y splits\n",
    "magic_telescope_X_trainDF, magic_telescope_y_trainDF = magic_telescope_trainDF.iloc[:, :-1], magic_telescope_trainDF.iloc[:, -1]\n",
    "magic_telescope_X_testDF, magic_telescope_y_testDF = magic_telescope_testDF.iloc[:, :-1], magic_telescope_testDF.iloc[:, -1]\n",
    "\n",
    "magic_telescope_X_train, magic_telescope_X_test = encode_X(magic_telescope_X_trainDF, magic_telescope_X_testDF)\n",
    "magic_telescope_y_train, magic_telescope_y_test = encode_y(magic_telescope_y_trainDF, magic_telescope_y_testDF)\n",
    "\n",
    "# To numpy arrays\n",
    "X_telescope_train = magic_telescope_X_train.to_numpy()\n",
    "X_telescope_test = magic_telescope_X_test.to_numpy()\n",
    "y_telescope_train = magic_telescope_y_train.to_numpy()\n",
    "y_telescope_test = magic_telescope_y_test.to_numpy()\n",
    "\n",
    "# Normalize input features\n",
    "X_telescope_train_norm, X_telescope_test_norm = normalize(X_telescope_train, X_telescope_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "id": "4SSoasDQSKXb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Magic telescope dataset KNN accuracy: 0.809\n"
     ]
    }
   ],
   "source": [
    "magic_telescope_knn = KNNClassifier(columntype=magic_telescope_column_types)\n",
    "magic_telescope_knn.fit(X_telescope_train, y_telescope_train)\n",
    "\n",
    "# Predict on test set\n",
    "score = magic_telescope_knn.score(X_telescope_test, y_telescope_test)\n",
    "print(\"Magic telescope dataset KNN accuracy: %.3f\" % score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2\n",
    "- Try it with k=3 and with normalization (input features normalized between 0 and 1). Use the normalization formula (x-xmin)/(xmax-xmin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Magic telescope dataset KNN accuracy: 0.832\n"
     ]
    }
   ],
   "source": [
    "# Train/Predict with normalization\n",
    "magic_telescope_knn.fit(X_telescope_train_norm, y_telescope_train)\n",
    "\n",
    "# Predict on test set\n",
    "score = magic_telescope_knn.score(X_telescope_test_norm, y_telescope_test)\n",
    "print(\"Magic telescope dataset KNN accuracy: %.3f\" % score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Discuss the accuracy results of using normalized data vs. unnormalized data*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The unnormalized accuracy for the magic telescope dataset was 80.9% while the normalized accuracy on the data was 83.2%. This 1.3% jump in accuracy seems very significant considering there are 12354 training examples and 6666 testing examples. Normalizing may not always provide better results but in this case it does."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3\n",
    "\n",
    "- Using your normalized data, create one graph with classification accuracy on the test set over k values. \n",
    "    - Use odd values of k from 1 to 15.\n",
    "- As a rough sanity check, typical knn accuracies for the magic telescope data set are 75-85%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Magic Telescore KNN 1\n",
      "Magic Telescore KNN 3\n",
      "Magic Telescore KNN 5\n",
      "Magic Telescore KNN 7\n",
      "Magic Telescore KNN 9\n",
      "Magic Telescore KNN 11\n",
      "Magic Telescore KNN 13\n",
      "Magic Telescore KNN 15\n"
     ]
    }
   ],
   "source": [
    "# Train/Predict with normalization using k=1,3,...,15\n",
    "knns = np.arange(1, 16, 2)\n",
    "accuracies = []\n",
    "for knn in knns:\n",
    "    print(\"Magic Telescore KNN %d\" % knn)\n",
    "    knnc = KNNClassifier(columntype=magic_telescope_column_types, knn=knn)\n",
    "    accuracies.append(knnc.fit(X_telescope_train_norm, y_telescope_train) \\\n",
    "        .score(X_telescope_test_norm, y_telescope_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Magic Telescope Accuracy vs K-Nearest Neighbors')"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Graph classification accuracy over k\n",
    "plt.plot(knns, accuracies)\n",
    "plt.xlabel('K-Nearest Neighbors')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Magic Telescope Accuracy vs K-Nearest Neighbors')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For the rest of the experiments use only normalized data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SIRG42TgSR4x"
   },
   "source": [
    "## 3. (10%) Use the regression variation of your algorithm (without distance weighting) for the [housing price prediction](https://www.cs.toronto.edu/~delve/data/boston/bostonDetail.html) problem.\n",
    "\n",
    "- Use this [training set](https://raw.githubusercontent.com/cs472ta/CS472/master/datasets/housing_train.arff) and this [test set](https://raw.githubusercontent.com/cs472ta/CS472/master/datasets/housing_test.arff).\n",
    "- Use Mean Square Error (MSE) on the test set as your accuracy metric for this case.\n",
    "    - Do not normalize regression output values\n",
    "- Graph MSE on the test set with odd values of k from 1 to 15\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "KBGUn43ASiXW"
   },
   "outputs": [],
   "source": [
    "# Load housing price prediction data\n",
    "\n",
    "# Train/Predict using k=1,3,...,15\n",
    "\n",
    "# Graph MSE over k\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v19fpixqTe-7"
   },
   "source": [
    "## 4. (15%) Repeat your experiments for magic telescope and housing using distance-weighted (inverse of distance squared) voting and discuss your results.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Magic Telescope Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "ZCPFUAGTS2sX"
   },
   "outputs": [],
   "source": [
    "# Train/Predict magic telescope using distance-weighted voting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Housing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/Predict housing using distance-weighted voting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Discuss your results*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. (10%) Use the k-nearest neighbor algorithm to solve the [credit-approval](https://archive.ics.uci.edu/ml/datasets/Credit+Approval) (credit-a) problem.\n",
    "\n",
    "- Use this [dataset](https://raw.githubusercontent.com/cs472ta/CS472/master/datasets/credit_approval.arff)\n",
    "    - Use a 70/30 split of the data for the training/test set\n",
    "- Note that this set has both continuous and nominal attributes, together with don’t know values. \n",
    "- Implement and justify a distance metric which supports continuous, nominal, and don’t know attribute values\n",
    "    - You need to handle don't knows with the distance metric, not by imputing a value.\n",
    "    - More information on distance metrics can be found [here](https://www.jair.org/index.php/jair/article/view/10182/24168).\n",
    "- Use your own choice for k.\n",
    "- As a rough sanity check, typical knn accuracies for the credit data set are 70-80%.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'credit_X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-053b7926a3bf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Load dataset and split into train/test sets\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mcreditDF\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'datasets/credit_approval.arff'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mcredit_X_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcredit_X_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcredit_y_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcredit\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcredit_XDF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcredit_yDF\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'credit_X_train' is not defined"
     ]
    }
   ],
   "source": [
    "# Load dataset and split into train/test sets\n",
    "creditDF = load_data('datasets/credit_approval.arff')\n",
    "credit_X_train, credit_X_test, credit_y_train, credit\n",
    "display(credit_XDF.head(2))\n",
    "display(credit_yDF)\n",
    "\n",
    "\n",
    "\n",
    "# Train/Predict credit-approval\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Explain and justify your distance metric*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oBBmeNQ7jvcQ"
   },
   "source": [
    "## 6. (15%) Use the scikit's KNN Classifier on magic telescope and KNN Regressor on housing and compare your results.\n",
    "\n",
    "- Try out different hyperparameters to see how well you can do. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OFQv70W2VyqJ"
   },
   "outputs": [],
   "source": [
    "# Train/Predict magic telescope using scikit's KNN\n",
    "\n",
    "# Train/Predict housing using scikit's KNN\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BqSFAXwlk3Ms"
   },
   "source": [
    "*Report your comparison*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cTlK-kijk8Mg"
   },
   "source": [
    "## 7. (optional 5% extra credit): For the best value of k for any one of the datasets, implement a reduction algorithm that removes data points in some rational way such that performance does not drop too drastically on the test set given the reduced training set.\n",
    "\n",
    "- Compare your performance on the test set for the reduced and non-reduced versions and give the number (and percentage) of training examples removed from the original training set. How well does your reduction algorithm work?\n",
    "    - Note that performance for magic telescope is classification accuracy and for housing it is mean squared error.\n",
    "    - Magic Telescope has about 12,000 instances and if you use a leave one out style of testing for your data set reduction, then your algorithm will run slow since that is n2 at each step.\n",
    "    - If you wish, you may use a random subset of 2,000 of the magic telescope instances.\n",
    "    - More information on reduction techniques can be found [here](http://axon.cs.byu.edu/~martinez/classes/478/slides/IBL.pdf).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5iY77P7gk1Nh"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "lab 1 - perceptron",
   "provenance": []
  },
  "interpreter": {
   "hash": "6b2efc4b102cc6878f14c71b1b299607eba1e6d0bb881d7beb2f5cad1213cf03"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 64-bit ('general': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
